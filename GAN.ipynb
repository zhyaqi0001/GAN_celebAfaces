{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN model generating images of human faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN model refers to Generative Adversarial Network which contains two neural network models to be trained against each other. The first neural network is named generator to generate fake samples and the second one is named discriminator to differentiate fake sample from the real ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<img src='GAN.png' width = 400 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelebA dataset is used here for the traing. Following shows what the data look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src = 'celeface.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class containing both generator and discriminator and optimazation of both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, image_batch, g_input_z):\n",
    "        self.image_batch = image_batch\n",
    "        self.g_input_z = g_input_z\n",
    "\n",
    "        with tf.variable_scope(\"generator\"):\n",
    "            self.g_output = self.generator()\n",
    "        self.gparams = tf.trainable_variables()\n",
    "\n",
    "        with tf.variable_scope(\"discriminator\"):\n",
    "            self.D1 = self.discriminator(self.image_batch)\n",
    "        with tf.variable_scope(\"discriminator\", reuse = True):\n",
    "            self.D2 = self.discriminator(self.g_output)\n",
    "        self.dparams = [v for v in tf.trainable_variables() if v.name.startswith('discriminator')]\n",
    "\n",
    "        # Declare losses, optimizers(trainers) and fid for evaluation\n",
    "        self.g_loss = self.g_loss_function()\n",
    "        self.d_loss = self.d_loss_function()\n",
    "        self.g_train = self.g_trainer()\n",
    "        self.d_train = self.d_trainer()\n",
    "        self.fid = self.fid_function()\n",
    "\n",
    "    def discriminator(self, x):\n",
    "        \"\"\"Compute discriminator score for a batch of input images.\n",
    "        \n",
    "        Inputs:\n",
    "        - x: TensorFlow Tensor of flattened input images, shape [batch_size, 784]\n",
    "        \n",
    "        Returns:\n",
    "        TensorFlow Tensor with shape [batch_size, 1], containing the score \n",
    "        for an image being real for each input image.\n",
    "        \"\"\"\n",
    "        \n",
    "        dlayer1 = layers.conv2d(x, 64, [5,5],strides = [2,2],padding = 'SAME',activation = tf.nn.leaky_relu)\n",
    "        dlayer2 = layers.conv2d(dlayer1, 128, [5,5],strides = [2,2],padding = 'SAME',activation = tf.nn.leaky_relu)\n",
    "        dlayer2 = layers.batch_normalization(dlayer2,axis = 3)\n",
    "        dlayer3 = layers.conv2d(dlayer2, 256, [5,5],strides = [2,2],padding = 'SAME',activation = tf.nn.leaky_relu)\n",
    "        dlayer3 = layers.batch_normalization(dlayer3,axis = 3)\n",
    "        dlayer4 = layers.conv2d(dlayer3, 512, [5,5],strides = [2,2],padding = 'SAME',activation = tf.nn.leaky_relu)\n",
    "        dlayer4 = layers.batch_normalization(dlayer4,axis = 3)\n",
    "        dlayer4 =  tf.reshape(dlayer4,[dlayer4.shape[0],512*4*4])\n",
    "        dlayer5 = layers.dense(dlayer4, 1, activation = tf.nn.sigmoid)\n",
    "        return dlayer5\n",
    "\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\"Generate images from a random noise vector.\n",
    "        \n",
    "        Inputs:\n",
    "        - z: TensorFlow Tensor of random noise with shape [batch_size, noise_dim]\n",
    "        \n",
    "        Returns:\n",
    "        TensorFlow Tensor of generated images, with shape [batch_size, 784].\n",
    "        \"\"\"\n",
    "        glayer1 = layers.dense(self.g_input_z, 512*16,activation = tf.nn.relu)\n",
    "        glayer1 = tf.reshape(glayer1, [self.g_input_z.shape[0], 4,4,512])\n",
    "        glayer1 = layers.batch_normalization(glayer1,axis = 3)\n",
    "        glayer2 = layers.conv2d_transpose(glayer1, 256,[5,5], strides = [2,2],padding = 'SAME', activation = tf.nn.relu)\n",
    "        glayer2 = layers.batch_normalization(glayer2,axis = 3)\n",
    "        glayer3 = layers.conv2d_transpose(glayer2,128,[5,5], strides = [2,2],padding = 'SAME', activation = tf.nn.relu)\n",
    "        glayer3 = layers.batch_normalization(glayer3,axis = 3)\n",
    "        glayer4 = layers.conv2d_transpose(glayer3,64,[5,5], strides = [2,2],padding = 'SAME', activation = tf.nn.relu)\n",
    "        glayer4 = layers.batch_normalization(glayer4,axis = 3)\n",
    "        glayer5 = layers.conv2d_transpose(glayer4,3,[5,5], strides = [2,2],padding = 'SAME', activation = tf.tanh)\n",
    "        \n",
    "        return glayer5\n",
    "\n",
    "    # Training loss for Generator\n",
    "    def g_loss_function(self):\n",
    "        g_loss = tf.reduce_mean(-log(self.D2)) \n",
    "        return g_loss\n",
    "\n",
    "    # Training loss for Discriminator\n",
    "    def d_loss_function(self):\n",
    "        d_loss = 0.5*tf.reduce_mean(-log(self.D1)-log(1- self.D2)) \n",
    "        return d_loss\n",
    "\n",
    "    # Optimizer/Trainer for Generator\n",
    "    def g_trainer(self):\n",
    "        g_train = tf.train.AdamOptimizer(args.learn_rate, args.beta1).minimize(self.g_loss, var_list = self.gparams) \n",
    "        return g_train\n",
    "\n",
    "    # Optimizer/Trainer for Discriminator\n",
    "    def d_trainer(self):\n",
    "        d_train = tf.train.AdamOptimizer(args.learn_rate, args.beta1).minimize(self.d_loss, var_list = self.dparams) \n",
    "        return d_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training of 7 epochs, Frechet Inception Distance (FID) between generated image and the real image is below 350. The generated images are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'output.png', width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The outputs do not look like real faces because of the limited training epochs. But the results clearly contains the basic feature of a face and further training would certainly improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
